{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee023607-8b91-4808-a143-90f3db032e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Path to the uploaded file\n",
    "zip_path = 'assesment_dataset_converter.zip'\n",
    "extract_path = 'assesment_dataset_converter/'\n",
    "\n",
    "# Create a directory to extract the zip file\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "# Extract the zip file\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "# List the extracted files to understand the contents\n",
    "extracted_files = os.listdir(extract_path)\n",
    "##extracted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbe410bc-c2a0-4380-8792-fdaa64cee72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# Load the dataset\n",
    "dataset_path = 'assesment_dataset_converter/assesment_dataset.tsv'\n",
    "dataset = pd.read_csv(dataset_path, sep='\\t')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "dataset.head()\n",
    "\n",
    "# Filter out genes with no expression in any condition\n",
    "filtered_dataset = dataset[(dataset.iloc[:, 1:] != 0).any(axis=1)].copy()\n",
    "\n",
    "# Display the filtered dataset\n",
    "##filtered_dataset.head()\n",
    "\n",
    "# Separate the conditions\n",
    "mock_reps = filtered_dataset[['mock_rep1', 'mock_rep2', 'mock_rep3']]\n",
    "sars_cov_reps = filtered_dataset[['sars_cov_rep1', 'sars_cov_rep2', 'sars_cov_rep3']]\n",
    "\n",
    "# Perform t-test between mock and sars_cov groups\n",
    "p_values = ttest_ind(mock_reps, sars_cov_reps, axis=1, equal_var=False).pvalue\n",
    "\n",
    "# Add p-values to the dataset using .loc\n",
    "filtered_dataset.loc[:, 'p_value'] = p_values\n",
    "\n",
    "# Filter genes with p-value < 0.05\n",
    "significant_genes = filtered_dataset[filtered_dataset['p_value'] < 0.05]\n",
    "\n",
    "# Display the significant genes\n",
    "##significant_genes.head()\n",
    "\n",
    "# Export the significant genes to a CSV file\n",
    "output_path = 'assesment_dataset_converter/significant_genes.csv'\n",
    "significant_genes.to_csv(output_path, index=False)\n",
    "\n",
    "# Display the path to the saved file\n",
    "##output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0c243ac-d5fa-4bb9-adb2-7648a2f6d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pip install gprofiler-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64c6804a-662a-48da-a7a1-562b39e55a1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from gprofiler import GProfiler\n",
    "\n",
    "# Initialize the gProfiler\n",
    "##gp = GProfiler(return_dataframe=True)\n",
    "\n",
    "# Extract the list of significant genes (Ensembl IDs)\n",
    "##significant_genes_list = significant_genes['converted_alias'].tolist()\n",
    "\n",
    "# Perform the enrichment analysis\n",
    "##enrich_results = gp.profile(organism='hsapiens', query=significant_genes_list, sources=['GO:MF', 'GO:BP', 'KEGG', 'REAC'])\n",
    "\n",
    "# Save the enrichment results to a CSV file\n",
    "##enrich_results.to_csv('assesment_dataset_converter/enrichment_results.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the results\n",
    "##enrich_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37074360-ad10-42cd-b368-56a76d3cafe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of Ensembl IDs to use as input in gProfiler website\n",
    "# Extract the list of Ensembl IDs starting with \"EN\"\n",
    "ensembl_ids = significant_genes['converted_alias']\n",
    "\n",
    "# Convert to a list\n",
    "ensembl_ids_list = ensembl_ids.tolist()\n",
    "\n",
    "# Display the list\n",
    "##ensembl_ids_list\n",
    "\n",
    "output_file_path = 'assesment_dataset_converter/ensembl_ids.txt'\n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    for ensembl_id in ensembl_ids_list:\n",
    "        file.write(f\"{ensembl_id}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eba6b830-0e8b-4f04-a519-e56ecf6abd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembl IDs -> converted_alias in significant_genes and converted_alias in converter\n",
    "#Entrez IDs -> initial_alias in converter\n",
    "\n",
    "# Load the converter file with the correct separator\n",
    "converter_path = \"assesment_dataset_converter/converter.tsv\"\n",
    "converter = pd.read_csv(converter_path, sep=',', quotechar='\"')\n",
    "\n",
    "# Save the corrected converter file to a new TSV file\n",
    "converter.to_csv('assesment_dataset_converter/converter_corrected.tsv', sep='\\t', index=False)\n",
    "\n",
    "# Load the converter file\n",
    "converter_corrected_path = 'assesment_dataset_converter/converter_corrected.tsv'\n",
    "converter_corrected = pd.read_csv(converter_corrected_path, sep='\\t')\n",
    "\n",
    "# Merge the significant genes with the converter to get Entrez IDs\n",
    "merged_df = significant_genes.merge(converter_corrected, left_on= significant_genes['converted_alias'], right_on=converter_corrected['converted_alias'])\n",
    "\n",
    "# Extract Entrez IDs\n",
    "entrez_ids = merged_df['initial_alias'].tolist()\n",
    "\n",
    "# Display the list of Entrez IDs\n",
    "##entrez_ids\n",
    "\n",
    "output_file_path_entrez = 'assesment_dataset_converter/entrez_ids.txt'\n",
    "\n",
    "with open(output_file_path_entrez, 'w') as file:\n",
    "    for entrez_id in entrez_ids:\n",
    "        file.write(f\"{entrez_id}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5da35af-355e-4c5e-91d6-9827daf7b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install bioservices if not already installed\n",
    "\n",
    "##!pip install bioservices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "299bb270-1d0e-44ef-864a-d79b5d104430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to map Entrez IDs to KEGG pathways:\n",
    "\n",
    "##from bioservices import KEGG\n",
    "\n",
    "# Create a KEGG service instance\n",
    "##k = KEGG()\n",
    "\n",
    "# Convert integers to strings using map() and list()\n",
    "##string_entrez_ids = list(map(str, entrez_ids))\n",
    "#print(string_entrez_ids)  \n",
    "\n",
    "# Organism code (e.g., hsa for Homo sapiens)\n",
    "##organism = \"hsa\"\n",
    "\n",
    "# Fetch KEGG pathway mappings\n",
    "\n",
    "# Open file for writing\n",
    "##output_file = \"pathways_output.txt\"\n",
    "\n",
    "##with open(output_file, 'w') as f:\n",
    "##    for gene_id in string_entrez_ids:\n",
    "##        try:\n",
    "##            pathways = k.get_pathway_by_gene(gene_id, organism)\n",
    "##            f.write(f\"Entrez ID: {gene_id}\\n\")\n",
    "##            for pathway in pathways:\n",
    "##                f.write(f\"{pathway}\\n\")\n",
    "##        except Exception as e:\n",
    "##            f.write(f\"Error fetching pathway for gene {gene_id}: {e}\\n\")\n",
    "\n",
    "##print(f\"Results written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698baf7a-d5c0-4ed1-9740-46ab6b1b12d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
